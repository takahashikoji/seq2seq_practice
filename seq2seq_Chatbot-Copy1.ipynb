{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takahashikoji/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import config\n",
    "from seq2seq_model import Chatbot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = open('movie_lines.txt', encoding = 'utf-8', errors = 'ignore').read().split('\\n')\n",
    "conversations = open('movie_conversations.txt', encoding = 'utf-8', errors = 'ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idline2 = {}\n",
    "for line in lines :\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5 :\n",
    "        #  idline2 は辞書型なので　dline2[_line[0]　をkey として、そのkey に対応する　_line[4]　をvalue　として代入している\n",
    "        idline2[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#　conversations の 最後の対話部分を抜き出している\n",
    "\n",
    "conversations_ids = []\n",
    "for conversation in conversations[:-1]:\n",
    "     # この処理よく分からない。\n",
    "    _conversation = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    \n",
    "    conversations_ids.append(_conversation.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversation_ids を question と answer に分ける作業\n",
    "# conversation は 　['L200', 'L201', 'L202', 'L203']　　こんな感じ\n",
    "#  idline2[conversation[i]] は　dict dline2 の辞書のkey　を指定しているので value  例えば　\"Well, there's someone I think might be --\",　が リストに格納される\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conversation in conversations_ids :\n",
    "    for i in range(len(conversation) -1) :\n",
    "        questions.append(idline2[conversation[i]])\n",
    "        answers.append(idline2[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正規表現をかます\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "cleand_questions = []\n",
    "for question in questions:\n",
    "    cleand_questions.append(clean_text(question))\n",
    "    \n",
    "cleand_answers = []\n",
    "for answer in answers:\n",
    "    cleand_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleand_questions と cleand_answers  を最大 len(25) 以内の長さに収めている\n",
    "\n",
    "short_questions = []\n",
    "short_answers = []\n",
    "i = 0\n",
    "for question in cleand_questions:\n",
    "    if 2 <= len(question.split()) <= 25:\n",
    "        short_questions.append(question)\n",
    "        short_answers.append(cleand_answers[i])\n",
    "    i += 1\n",
    "cleaned_questions = []\n",
    "cleaned_answers = []\n",
    "i = 0\n",
    "for answer in short_answers:\n",
    "    if 2 <= len(answer.split()) <= 25:\n",
    "        cleaned_answers.append(answer)\n",
    "        cleaned_questions.append(short_questions[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2_count   cleaned_questions    cleand_answers の 全ての　vocab の出現頻度を数えている\n",
    "\n",
    "word2count = {}\n",
    "for question in cleaned_questions:\n",
    "    for word in question.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "for ansswer in cleaned_answers:\n",
    "    for word in answer.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_questions = 15\n",
    "questionswords2int = {}\n",
    "word_number = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold_questions:\n",
    "        questionswords2int[word] = word_number\n",
    "        word_number += 1\n",
    "threshold_answers = 15\n",
    "answerswords2int = {}\n",
    "word_number = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold_answers:\n",
    "        answerswords2int[word] = word_number\n",
    "        word_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 出現頻度　15回以上のword を new_vocab に追加する\n",
    "\n",
    "threshold = 15\n",
    "new_vocab = []\n",
    "\n",
    "for key in word2count.keys() :\n",
    "    if word2count[key] >= threshold :\n",
    "        new_vocab.append(key)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list 同士の足し算\n",
    "\n",
    "new_vocab = ['<PAD>', '<GO>', '<UNK>', '<EOS>'] + new_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_id = {word:i for i, word in enumerate(new_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_word = {i:word for i, word in enumerate(new_vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encode処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_data = []\n",
    "\n",
    "def data_encode(data, word_to_id) :\n",
    "\n",
    "    for i in range(len(data)) :\n",
    "\n",
    "        encoded_line = []\n",
    "        words = cleaned_questions[i].split()     # list の word 毎に　区切って入れる。\n",
    "\n",
    "        for word in words :\n",
    "\n",
    "            if word not in word_to_id.keys() :\n",
    "                encoded_line.append(word_to_id['<UNK>'])\n",
    "\n",
    "            else :\n",
    "                encoded_line.append(word_to_id[word])\n",
    "\n",
    "\n",
    "        encoded_data.append(encoded_line)\n",
    "    \n",
    "    \n",
    "    return np.array(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_questions = data_encode(cleaned_questions, word_to_id)\n",
    "encoded_answers = data_encode(cleaned_answers, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  [word_to_id['<EOS>']]   と書く事で　int を list に出来る  　そして　これで　target データの末尾に　<EOS> を追加出来た。\n",
    "encoded_answers = [sequence + [word_to_id['<EOS>']] for sequence in encoded_answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Chatbot(config.LEANING_RATE, \n",
    "                config.BATCH_SIZE, \n",
    "                config.ENCODING_EMBED_SIZE, \n",
    "                config.DECODING_EMBED_SIZE, \n",
    "                config.RNN_SIZE, \n",
    "                config.NUM_LAYERS,\n",
    "                len(new_vocab), \n",
    "                word_to_id, \n",
    "                config.CLIP_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "# saver 最後に学習したモデルの保存を行う。　　max_to_keep　保持する最新のチェックポイントの最大数。　デフォルトは５である。\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 学習 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_pad_que(batch_of_sequences, word_to_id) :\n",
    "    max_sequence_length = max([len(sequence) for sequence in batch_of_sequences])\n",
    "    return [sequence +  [word_to_id['<PAD>']] * (max_sequence_length - len(sequence)) for sequence in batch_of_sequences]\n",
    "\n",
    "def apply_pad_ans(batch_of_sequences, word_to_id) :\n",
    "    max_sequence_length = max([len(sequence) for sequence in batch_of_sequences])\n",
    "    return [sequence + [word_to_id['<PAD>']] * (max_sequence_length - len(sequence)) for sequence in batch_of_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2423\n",
      "4847\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_questions)// 64)\n",
    "print(len(encoded_answers)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(labels, predicts):\n",
    "    return np.mean(np.equal(labels, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 26)\n",
      "(64, 26)\n",
      "EPOCH: 0/2 Epoch accuracy: 0.001201923076923077 Epoch loss: 8.258495330810547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  len(X_batch[0] , len(y_batch[0]   はpaddingで固定されているので同じ値が入る。その値を持つ６４個の要素を一つのリスト内に入れている\n",
    "\n",
    "\n",
    "for i in range(1) :\n",
    "    epoch_accuracy = []\n",
    "    epoch_loss = []\n",
    "    for ii in tqdm(range(len(encoded_questions[:64]) // config.BATCH_SIZE)) :\n",
    "        \n",
    "        starting_id = ii * config.BATCH_SIZE\n",
    "        \n",
    "        batch_of_questions = encoded_questions[starting_id : starting_id + config.BATCH_SIZE]\n",
    "        # padding処理した　encoded_questions\n",
    "        X_batch = apply_pad_que(batch_of_questions, word_to_id)\n",
    "        batch_of_answers = encoded_answers[starting_id : starting_id + config.BATCH_SIZE]\n",
    "        # padding処理した　encoded_answers\n",
    "        y_batch = apply_pad_ans(batch_of_answers, word_to_id)\n",
    "        \n",
    "        \n",
    "        feed_dict = {model.inputs : X_batch,\n",
    "                               model.targets : y_batch,\n",
    "                               model.keep_probs : config.KEEP_PROBS,\n",
    "                                model.encoder_seq_len : [len(X_batch[0])] * config.BATCH_SIZE,\n",
    "                                model.decoder_seq_len : [len(y_batch[0])] * config.BATCH_SIZE\n",
    "                                }\n",
    "        \n",
    "        # Chatbot class で定義した　loss, opt, predictions　を定義している\n",
    "        cost, _, preds = session.run([model.loss, model.opt, model.predictions], feed_dict=feed_dict)\n",
    "        print(np.array(y_batch).shape)\n",
    "        print(np.array(preds).shape)\n",
    "        \n",
    "        if len(np.array(y_batch[0])) == len(np.array(preds[0])) :\n",
    "            epoch_accuracy.append(get_accuracy(np.array(y_batch), np.array(preds)))\n",
    "            \n",
    "        elif len(np.array(y_batch[0])) <= len(np.array(preds[0])) :\n",
    "            y_batch_ = np.empty((64, len(np.array(preds[0]))))\n",
    "            for i, sequence in enumerate(np.array(y_batch)) :\n",
    "                max_sequence_length = len(preds[0])\n",
    "                pad_width = (0, max_sequence_length -len(sequence))\n",
    "                y_batch_[i] = np.pad(y_batch[i], pad_width, 'constant', constant_values=0)\n",
    "                \n",
    "\n",
    "            print('y_batch_', y_batch_.shape)\n",
    "            epoch_accuracy.append(get_accuracy(np.array(y_batch_), np.array(preds)))\n",
    "#             max_sequence_length = len(np.array(preds[0]))\n",
    "#             y_batch = [sequence +  [word_to_id['<PAD>']] * (max_sequence_length - len(sequence) for sequence in np.array(y_batch))]\n",
    "\n",
    "#             for i, sequence in enumerate(np.array(y_batch)) :\n",
    "#                 max_sequence_length = len(preds[0])\n",
    "#                 y_batch[i] = sequence + [word_to_id['<PAD>']] * max_sequence_length - len(sequence)\n",
    "                                                            \n",
    "#             epoch_accuracy.append(tf.metrics.accuracy(np.array(y_batch), np.array(preds)))\n",
    "                                                            \n",
    "       \n",
    "        elif len(np.array(preds[0])) <= len(np.array(y_batch[0])) :\n",
    "            preds_ = np.empty((64,len(np.array(y_batch[0] ))))\n",
    "            for i, sequence in enumerate(np.array(preds)) :\n",
    "                max_sequence_length = len(y_batch[0])\n",
    "                pad_width = (0, max_sequence_length -len(sequence))\n",
    "                preds_[i] = np.pad(preds[i], pad_width, 'constant', constant_values=0)\n",
    "                \n",
    "            print('preds_', preds_.shape)\n",
    "            epoch_accuracy.append(get_accuracy(np.array(y_batch), np.array(preds_)))\n",
    "                 \n",
    "#             max_sequence_length = len(np.array(y_batch[0]))\n",
    "#             preds = [sequence + [word_to_id['<PAD>']] * (max_sequence_length - len(sequence) for sequence in np.array(preds))]\n",
    "            \n",
    "#             for i, sequence in enumerate(np.array(preds)) :\n",
    "#                 max_sequence_length = len(y_batch[0])\n",
    "#                 preds[i] = sequence + [word_to_id['<PAD>']] * max_sequence_length - len(sequence)            \n",
    "        \n",
    "        \n",
    "            \n",
    "    epoch_loss.append(cost)\n",
    "        \n",
    "    print('EPOCH: {}/{}'.format(i, config.EPOCHS),'Epoch accuracy: {}'.format(np.mean(epoch_accuracy)),\\\n",
    "          'Epoch loss: {}'.format(np.mean(epoch_loss)))\n",
    "    \n",
    "    \n",
    "    saver.save(session, \"checkpoint/chatbot_{}.ckpt\".format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_string_to_int(question, word_to_id) :\n",
    "    question = clean_text(question)\n",
    "    return [word_to_id.get(word, word_to_id['<UNK>']) for word in question.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your word: Hi\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inference_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f1bc647d7ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfake_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     prediceted_answer = session.run(inference_output, feed_dict={\n\u001b[0m\u001b[1;32m     16\u001b[0m                                                                             \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfake_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                                             \u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inference_output' is not defined"
     ]
    }
   ],
   "source": [
    "#　Chatbot 対話部分\n",
    "from seq2seq_model import Chatbot\n",
    "\n",
    "while (True) :\n",
    "    \n",
    "    question = input(\"your word: \")\n",
    "    if question == 'Goodbye' :\n",
    "        break\n",
    "        \n",
    "    question = convert_string_to_int(question, word_to_id)\n",
    "    question = question +[word_to_id['<PAD>']] * (25 - len(question))\n",
    "    fake_batch = np.zeros((config.BATCH_SIZE, 25))\n",
    "    fake_batch[0] = question\n",
    "    \n",
    "    prediceted_answer = session.run(inference_output, feed_dict={\n",
    "                                                                            inputs: fake_batch, \n",
    "                                                                            keep_prob : 0.5\n",
    "    })[0]\n",
    "   \n",
    "    answer = ''\n",
    "    # 第二引数は 配列の指定\n",
    "    for i in np.argmax(predicted_answer, 1) :\n",
    "        \n",
    "        if id_to_word[i] == 'i' :\n",
    "            token = 'I'\n",
    "        elif id_to_word[i] == '<EOS>' :\n",
    "            token = '.'\n",
    "        elif id_to_word[i] == '<UNK>' :\n",
    "            token = 'unk'\n",
    "        else :\n",
    "            token = ' ' + id_to_word[i]\n",
    "        answer += token\n",
    "        if token == '.' :\n",
    "            break\n",
    "            \n",
    "    print('Chatbot:' + answer )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
